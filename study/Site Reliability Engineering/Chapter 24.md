## Chapter 24 크론을 이용한 분산된 주기적 스케줄링

### 크론

일단 하나의 머신 위의 크론을 살펴보자

#### 신뢰성 관점에서의 크론

- 장애 도메인은 단 하나의 머신
- (crond 또는 해당 머신을 재시작 하더라도) 영구적으로 보관할 상태는 crontab 설정 뿐
- 아나크론(anacron)은 예외. 아나크론은 다운됐을 때 못 했던 작업을 마저 한다. 따라서 작어버들의 마지막 실행 시간을 파일에 관리해야 한다.

### 크론 작업과 멱등성

당연히 멱등한 작업도, 그렇지 않은 작업도 있다. 그런데 메일발송처럼 두 번 실행된 작업을 되돌리기 어렵거나 불가능한 작업들 때문에 우리는 보통 시스템이 잘못된 상태가 되는 것보다는 '변경 없이 실패(fail closed)'하는 방식을 선호한다.

### 대용량 시스템 내에서의 크론

크론 서비스를 하나의 머신이 아닌 대용량 시스템에 배포하려면 어떻게 해야 할까?

#### 인프라스트럭처의 확장

크론을 한 머신에서 운영하는 것은 신뢰성 측면에서는 최악이다.

1. (이미 신뢰성이 충분히 높아야 하는) 데이터센터 스케줄링 시스템에게 직접 머신을 관리하여 서비스를 실행하게 한다.
2. 머신이 고장나도 발견할 수 있다. 그러나 다른 머신에서 다시 시작하면 그동안 지연되는 시간 자체가 critical한 경우가 있을 수 있다. ex) 5분 마다 실행하는데 2분의 지연이 생김
3. 이런 경우에는 여분의 서비스를 미리 배치해 놓으면 도움이 될 수 있다.

#### 요구사항의 확장

- 데이터센터에 크론 작업이 필요로 하는 자원의 양을 사전에 미리 파악해야 한다. 지연이 발생할 수 있기 때문.
- 크론 프로세스의 분리는 부분적인 실패를 만들 수 있다. 크론 복구 절차를 반드시 수립해야 한다.
- 데이터센터 일부 장애가 발생하더라도 크론 서비스가 잘 동작하도록 구축해야 한다.


### 구글에서 구현한 크론 서비스

크론 서비스를 대용량 분산 환경에 배포할 때의 신뢰성을 확보하기 위해 반드시 해결해야 할 문제들

#### 크론 작업의 상태 추적하기

- 데이터를 분산 저장소에 저장하는 방법
- 크론 서비스 자체에 상태의 일부를 저장하는 서비스를 덧붙이는 방법 (구글이 선택)

구글의 선택 이유

- GFS나 HDFS 등의 분산 파일 시스템은 매우 큰 파일에 적합한 반면, 크론 작업은 크기가 매우 작음.
- 크론같이 장애의 영향이 큰 기반 서비스는 다른 서비스에 대한 의존도를 최소화해야 함.

#### Paxos의 활용

크론 서비스의 여러 복제 서버를 배포할 때, Paxos 분산 합의 알고리즘을 사용하여 상태의 일관성을 확보

각 크론 작업이 시작한/끝난 정보를 복제 서버의 과반수에 동기화

#### 리더와 그 팔로워들의 역할

##### 리더의 역할

실질적으로 크론 작업을 실행할 수 있는 유일한 복제 서버

Paxos는 동기적으로 통신하므로, 과반수의 복제 서버들이 실행한다는 신호를 받기 전까지는 실제 크론 작업이 실행되지 않음. 이렇게 해야 장애가 발생했을 때 팔로워들이 작업 진행 상황을 파악할 수 있다.

리더 역할을 종료할 때는 데이터센터 스케줄러와의 상호 작용을 그 즉시 중단해야 한다. Dead lock 등 방지.

##### 팔로워의 역할

작업의 실행을 통지받으면 해당 작업의 다음 예약 시간을 수정

리더가 고장났을 때 새로운 리더는 1분 안에 뽑아야 함

##### 부분적 실패의 해결

작업이 실행은 되었지만 리더가 고장나기 전까지는 완료 여부를 모르는 상황을 가정. 리더의 RPC 호출이 성공했는지 알기 위해서는 다음 중 하나를 만족해야 한다.

- 리더 재선출 이후의 외부 시스템 호출 작업은 반드시 멱등해야 함
- 작업의 완료 여부를 정확하게 판단하려면 외부 시스템을 호출하는 모든 작업의 상태를 조회할 수 있어야 함

이건 매우 어렵지만 해야 한다..

멱등성을 위한 한 가지 방법은, 작업을 실행할 때 그 이름과 시간을 모든 복제 서버와 함께 공유하는 것이다. 중복 실행을 방지하는 방법이다.

리더가 고장나고 오랜 시간이 흘러 리더가 바뀐 경우, 작업의 이름이 시작 시간을 포함한다면 그 작업을 다시 실행하지는 않을 것이다. 중복 실행을 방지할 수 있다.

#### 상태의 저장

Paxos는 상태의 변경에 대한 연속적인 로그이며, 상태의 변경은 동기적으로 추가된다. 이것이 상태의 저장에 다음 문제점을 만든다.

- 로그를 무한정 기록할 수는 없으므로 로그 자체의 크기가 작아야 한다.
- 로그를 다른 어딘가에 저장해야 한다.

크기 :  현재 상태의 스냅샷을 만드는 것으로 해결 (+1을 천 번 저장하지 않고, +1000 저장)

저장소 : 구글은 외부 저장소와 크론 서비스 자체에 저장소를 추가하는 방법을 조합했다. 로그와 스냅샷 모두 복제 서버들의 로컬 디스크에 저장. 스냅샷은 분산 파일 시스템에 백업도.

#### 대용량 크론 서비스의 운영

분산 시스템의 **천둥 소리(thundering herd)** 문제가 마찬가지로 적용된다. 예를 들어, 매일 실행할 크론 작업은 보통 자정으로 설정하는 경향이 있다.

이 경우 기존의 설정은 [ 0 0 * * * ]다. 구글은 여기에 물음표로 랜덤 값을 쓸 수 있도록 하여 작업의 실행을 분산시켰다. [ ? ? * * * ] 같이.
