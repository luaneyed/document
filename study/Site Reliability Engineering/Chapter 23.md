## Chapter 23 치명적인 상태 관리하기: 신뢰성을 위한 분산에 대한 합의

**이미 증명되고 테스트된 분산 합의 시스템을 이용하라**

##### CAP 이론
아래 세 가지를 동시에 만족할 수 없음
- 각 노드에서의 데이터에 대한 일관성 확인
- 각 노드에서의 데이터의 가용성
- 네트워크 파티션에 대한 장애 허용

**Eventual Consistency의 일관성 문제는 너무 복잡해서 반드시 db 수준에서 해결되어야 한다**

### 합의는 왜 필요할까: 분산 시스템 간 협업의 실패

#### 사례 연구 1: 분리된 뇌(split-brain) 문제

- 파트너와 연결할 수 없게 되었을 때 파트너의 파일의 소유권을 강제로 차지. **STONITH (Shoot The Other Node in the Head)** 명령을 파트너 노드로 전달.
- 네트워크 문제 등으로 둘이 같이 소유권을 가진다고 생각하거나, 둘 다 종료되어버릴 수 있음
- 타임아웃으로만 리더 선출 문제를 해결하려는 것이 문제. 리더 선출은 단순한 Health Check만으로는 올바르게 해결할 수 없음

#### 사례 연구 2: 사람이 개입해야 하는 장애 조치
master node가 고장났을 때, 위 문제를 피하기 위해 사람이 직접 slave node를 선택하여 승격시키도록 한다면 운영 업무가 지나치게 증가한다.

#### 사례 연구 3: 그룹-멤버십 알고리즘의 오류
- 정확성이 입증되었으며, 포괄적으로 테스트된 분산 합의 알고리즘 구현을 통해서만 해결할 수 있다.

### 분산에 대한 합의가 동작하는 방식
- 보통 **비동기 분산 합의**에 관심을 갖는다
- 분산 합의 알고리즘은 **충돌-실패**(충돌 노드 영구 제외) 혹은 **충돌-복구** 방식을 사용한다.
보통 충돌은 일시적이므로 후자가 훨씬 유용.
- 비잔틴 실패(증상이 각기 다른 실패) 혹은 논비잔틴 실패를 다룬다.
- 제한된 시간 내에서 비동기 분산 합의 문제를 해결하는 것은 불가능 (증명됨)

#### Paxos 살펴보기: 예제 프로토콜
1. 제안자가 수신자에게 일련 번호 전달
2. 수신자는 더 높은 일련 번호를 처리 중이지 않을 경우에만 제안 수용
3. 제안자는 필요에 따라 더 높은 일련 번호로 재요청
4. 일련 번호는 Unique
5. 수신자들 중 과반수가 제안을 수용하면 제안자는 실제 값을 가진 메시지를 전송
6. 사실 그다지 유용하지는 않다.

### 분산 합의를 위한 시스템 아키텍처 패턴

- 분산 합의 알고리즘의 특징 : low-level, 원시적
- 더 높은 수준의 컴포넌트들이 현실적인 기능을 제공해야 함

#### 신뢰할 수 있는 복제된 상태 머신

복제된 상태 머신(Replicated State Machine, RSM)는 여러 프로세스를 통해 동일한 작업을 동일한 순서로 실행하는 시스템. 분산 시스템 컴포넌트 구축을 위한 기본 단위다.

#### 신뢰할 수 있는 복제된 데이터 저장소와 설정 저장소

- 복제된 저장소는 중요한 작업을 실행할 때 합의 알고리즘을 사용
- 분산 시스템에서 timestamp의 사용은 문제가 많음. 정확한 시간 동기화가 불가능하기 때문.

#### 리더 선출을 이용한 고가용성 프로세싱

- 분산 시스템의 리더 선출은 분산 합의와 유사한 문제다.
- 단일 리더 메커니즘은 기본적인 수준의 동등한 실행을 보장하기 위한 방법이다.

#### 분산 조정(Coordination)과 잠금 서비스

**장벽(barrier)**

- ex) 맵리듀스에서 Map 다 끝내고 나서 Reduce
- 한 프로세스로 구현할 수 있지만, 그렇게 한다면 spof

**잠금(lock)**은 RSM으로 구현할 수 있는 또 다른 형태의 조정 요소.

#### 신뢰할 수 있는 분산 큐와 메시지

- 큐의 단점은 큐의 손실이 전제 시스템을 고장낸다는 것이다.
- 큐를 RSM으로 구축하면 이런 위험을 최소화할 수 있음.

**원자적 전파(atomic broadcast)**는 메시지를 안정적이면서도 동일한 순서로 모든 수신자에게 전달하기 위한 기본적인 요소.

**작업을 위한 분산 큐** 패턴은 로드밸런싱 장치에서 큐를 사용한다.

### 분산 합의의 성능

합의 알고리즘의 구현은 느릴 수 있지만 그 성능을 향상시킬 수 있는 다양한 방법들이 존재한다. 실제로 구글은 매우 효율적으로 운영하고 있다! 하지만 이것은 구글의 확장성 덕분에 가능한 것이 아니다. 확장성은 오히려 단점이다. 데이터셋의 크기가 너무 크며, 시스템들이 지리적으로 멀리 떨어져 있기 때문이다.

대부분의 합의 시스템은 리더를 사용하고, 이런 시스템에서의 모든 요청들은 리더에게 전달된다. 따라서 시스템의 성능은 클라이언트의 위치에 따라 rtt가 달라지는 것 때문에 천차만별이다.

#### Multi-Paxos: 메시지의 흐름에 대한 자세한 내용

Multi-Paxos 프로토콜은 **강력한 리더 프로세스**를 사용한다.

???

#### 읽기 작업 부하의 확장

읽기를 할 때 모든 변경 사항의 일관성을 보장하고 최신 데이터를 읽으려면 다음 중 하나를 해야 한다.

- 읽기 전용 합의 작업 수행
- 최신 데이터임을 보장하는 복제 서버로부터 데이터를 읽기
- 과반수 임대 사용

#### 과반수 임대

읽기 작업에 대한 지연응답을 최소화하고 처리량을 증가시키는 것을 목표로 가장 최근에 개발된 분산 합의 성능 최적화 기법.

일부 복제 서버가 데이터의 일부의 읽기 작업을 임대하고 쓰기 성능을 희생하는 방법

#### 분산 합의 성능과 네트워크 지연응답

두 가지 물리적 제약 : RTT, 데이터 영속 저장에 소요되는 시간

##### RTT

지역 네트워크 내에서의 성능은 전통적 DBMS의 비동기 master-slave 시스템과 견줄 만하다. 그러나 분산 합의 시스템이 제공하는 가용성의 장점은 멀리 떨어진 복제 서버에서 크다.

많은 합의 시스템이 TCP/IP를 사용하는데,

- 3-way handshake를 하면 시작이 너무 길어지고
- keep-alive traffic을 사용하려면 관련 자원을 계속 들고 있어야 하므로

각 지역별 프록시 풀을 만들어서 연결을 계속 들고 있는 것이 좋다.

#### 성능에 대한 고려: Fast Paxos

광역 네트워크 상에서 Paxos의 성능을 향상시킨 버전

각 클라이언트는 제안 메시지를 리더를 통하지 않고 수락자 그룹의 각 멤버에게 직접 전달 가능

본질적으로 Paxos보다 빠를 것 같지만, 사실은 더 느릴 때도 있음

#### 안정적인 리더

결국 리더가 병목이다. 모든 페이로드가 지나가기 때문. Transaction ID Hash 등을 이용하여 회전형 리더십 시스템으로 성능 향상을 시도하는 경우도 있다.

#### 일괄 처리(batching)

리더가 파이프라인에 메시지들을 가지고 있다가, 한 번에 처리하면 좋다.

#### 디스크 접근

동의한 제안들 로그가 없으면, 충돌이 일어난 경우 고장날 수 있다. RSM도 복구를 위한 트랜잭션 로그를 기록해야 한다.

### 분산 합의 기반 시스템의 배포

복제 서버의 수와 그 위치를 반드시 고려

#### 복제 서버의 수

합의 기반 시스템은 보통 **과반수**를 이용해 동작한다.

- 2n+1 개의 서버가 있으면 n개의 장애를 허용
- 비잔틴 장애 허용을 하려면 3n+1 개의 서버가 n개의 장애를 허용
- 따라서 논비잔틴의 경우 최소 세 개를 배포해야 장애를 허용
- 그러나 우리는 유지보수도 해야 하니까 다섯 개는 하자
- 결국 신뢰성에 대한 수요, 유지보수의 빈도, 각종 위험 요소, 성능, 비용의 tradeoff

#### 복제 서버의 위치

- 재해로부터의 복구 상황을 고려
- 소프트웨어 버그 고려
- 시스템 관리자의 실수 고려
- (RTT 등을 통한) 클라이언트의 인지 여부 고려

#### 수용량과 로드밸런싱

- 복제 서버를 추가하는 것이 가용성을 감소시킬 수 있다. 2/5 -> 40%, 2/6 -> 33%

##### 과반수 조합

노드 간 RTT가 서로 최대한 비슷한 것이 좋다 (362p 참고)
